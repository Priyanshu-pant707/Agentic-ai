# LLM
- large language models 


## what is an LLM?
- a large language model is a type of AI model trained on massive amount of text data to understand ,generate , and reason with human language.
- it is based on neural networks (mainly transformers) and can process natural language in a way that mimics human understading 

``` 
A LLM model is a deep learning model trained to predict next word (token) in a sequence of text , thereby learning grammar, context ,reasoning and world knowledse from data.

```




## core idea :
- LLMs are built on a self-supervised learning process  - they learn pattern from unlabled data by predicting missing parts of text.
Over time, this enable them to : 
- understand context.
- generate coheretn sentences
- solve problems
- answer questions
- plan and reason over multi-step tasks.



## Architecture  : Transformer
-  the foundation fo LLMs
-  the transformer arcitecture revolutionized AI by enabling parallel process and long-range dependencies in text.


