# Hugging Face &  Open-Source LLMs


## what is huggingface?
- a platform for hosting the ML models,datasets and tools.
- like github , but for ai models.
- running ai applications directly from the browser via spaces.


## Why do people aways say "You Need a GPU for AI"?
- because GPUs are built for doing many math calculations at the same time - which is exactly what ai models need. 

- GPU ->  Graphics Processing Unit
- originially made for games , to draw images (lots of pixels,colors in lesser time).
- it has thousands of small cores that can do:
   - Matrix multiplications
   - Vector operations
   - Math needed for AI.
- A core is like a mini brain inside your computer's processor. Each core can do one task .



## Can you Run AI models on a CPU?

- yes can run small AI models on a cpu, especially low-size models,and it's a great way to get started without needing a GPU.

- small LLM like distilBERT,Tinylama,GPT32-small,mistra-7B(with quantization)

- Tasks like :
   - text classification.
   - Question-answering
   - Basic text generation
   - Sentimental analysis
-  these lightweight models that don't need thousands of GPU cores.



## What is a Quantized Model ?
- Quatized means reducing the model size by storng numbers with lower precision making them :
  - Fast to load.
  - lighter in size (less storage required).


## Model Parameters?

