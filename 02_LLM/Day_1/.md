# LLM 
- large language model


## What is  LLM ?
- it is a type of artificial intelligence that can understand  generate , and interact using human language.
- Trained on massive text data like books, websites , Wikipedia,etc.
- eg -> chatGPT, Claude, Gemini.

- think of LLM as a very advanced auto-complete engine,but for full conversations, code , eassays, and more.


## Famous LLMs
- GPT(OpenAI) - ChatGPT,GPT-4o
- Claude (Anthropic - AI safely and research company)
- LLaMa (Meta , open-source)
- Mistral (open-weight French LLM)


```
Each LLM has different strength,speed accuracy,openess, and multilingual abilities
```




## How LLM actually works ?

1. ***Tokenization*** : Breaks your text into smaller units (token)
2. ***Embeddings*** : Converts token into numbers (vectors).
 -  list of numbers
 -  representing meaning of the token in mathematical space.

3. ***Transformer*** :uses an attention mechanism to decide which words matter.
  -  what is important?
  - what words are related?
  - what to focus on?

4. ***Prediction*** :  Generates the next token (word/letter) based on training.
 - Depends on :
   - the training data.
   - the prompt
   - temprature (creativity)
   - max token length


--- 

 - the token with the highest pobability is not always chosen , and that's beacuse of sampling strategies and decoding setting like :



1. Temperature :
-  controls the randomness
- lower : more deterministic (almost always picks top token)
- high: more diverse,sample from wider range.


2. Top k-Sampling :
 - only consider the top k-most probable tokens,
 - randomly sample from them based on their probabilities
 - discard the rest.

3. Top -p Sampling (Nucleus Sampling)
 - picks the smallest set of tokens whose cumulative probability is >=p
 - then samples within that set.
 - more adaptive than top -k .

4. Min - p  (minimum probability cutoff)
 - discards toekns whse prbability is below a threshold
 - helps avoid unlike grabage output.

 